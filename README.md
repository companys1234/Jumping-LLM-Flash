# Jumping-LLM-Flash
Jumping-LLM-Flash - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Å–±–æ—Ä–∫–∏ –º–∞–ª–µ–Ω—å–∫–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è, –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, –∏ —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏.
–ê —Ç–∞–∫–∂–µ –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞. 


Jumping-LLM-Flash is a library for quickly building small language models, focusing on optimizing training, inference, and data manipulation.
It also aims to reduce the amount of code needed to build a complete pipeline.

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞(Installation)
```bash
git https://github.com/companys1234/Jumping_LLM_Flash.git
```
# –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã(Test cases)
LLaMa 2 ü¶ô


<a href="https://colab.research.google.com/drive/1J0AtBk9unn7vXKNoF5-NixcIFuWXK5Pw?usp=sharing">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
</a>


Grok 1 ü™ê


<a href="https://colab.research.google.com/drive/1GMzXgc83RSJmvEabio6oEdlEC1f_TqtS?usp=sharing">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
</a>
